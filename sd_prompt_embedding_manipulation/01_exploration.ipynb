{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f7f7f55-b870-4af4-9f0f-721f5acaf473",
   "metadata": {},
   "source": [
    "# 1 - Prepare an image generation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ed853f-4055-47ee-8a47-52e2a386a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from diffusers import StableDiffusionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90684a66-f136-40d2-a17e-2f3a07a7d1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c1ceb1-0cff-4430-acc1-5223dcc4ff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a bouquet of tulips\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc3073e-7da1-47b7-816b-c925d9b78c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_embeds, negative_prompt_embeds = pipeline.encode_prompt(\n",
    "    prompt,\n",
    "    device=\"cuda\",\n",
    "    num_images_per_prompt=1,\n",
    "    do_classifier_free_guidance=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f1267c-da50-4e72-a52b-e35067218dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(prompt_embeds, negative_prompt_embeds, seed=0):\n",
    "    with torch.no_grad():\n",
    "        generator = torch.Generator().manual_seed(0)\n",
    "        return pipeline(\n",
    "            prompt_embeds=prompt_embeds,\n",
    "            negative_prompt_embeds=negative_prompt_embeds,\n",
    "            generator=generator\n",
    "        ).images[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f2797b-4a69-441d-b185-e9bca78de766",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_image(prompt_embeds, negative_prompt_embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f25c454-3eaf-489e-8781-a7806ccb74ea",
   "metadata": {},
   "source": [
    "## 2 - Explore properties of prompt embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861c82bc-404e-470a-819f-e77cd203147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_prompt_embed_histogram(x, range, bins=20):\n",
    "    fig, ax = plt.subplots()\n",
    "    n, bins, patches = ax.hist(x, bins=bins, range=range)\n",
    "    ax.set_xlabel(\"Value\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.set_title(f\"Histogram of prompt embed values. (Histogram range: {range})\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_per_token_mean(np_prompt_embeds):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(\n",
    "        np.arange(np_prompt_embeds.shape[1]),\n",
    "        np_prompt_embeds[0].mean(axis=-1),\n",
    "        color='green',\n",
    "        marker='o',\n",
    "        linestyle='dashed',\n",
    "        linewidth=2,\n",
    "        markersize=12,\n",
    "    )\n",
    "    ax.set_xlabel(\"Token Embedding Index\")\n",
    "    ax.set_ylabel(\"Token Embedding Mean\")\n",
    "    ax.set_title(\"Per-Token-Embedding Means\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def log_prompt_embed_properties(prompt_embeds):\n",
    "    print(f\"Prompt embeds shape: {prompt_embeds.shape}\")\n",
    "    print(f\"Prompt embeds range: [{prompt_embeds.min()}, {prompt_embeds.max()}]\")\n",
    "    print(f\"Prompt embeds mean: {prompt_embeds.mean()}\")\n",
    "\n",
    "    np_prompt_embeds = prompt_embeds.detach().cpu().clone().numpy()\n",
    "\n",
    "    show_prompt_embed_histogram(np_prompt_embeds.flatten(), [-2.0, 2.0])\n",
    "    show_prompt_embed_histogram(np_prompt_embeds.flatten(), [-10.0, 10.0])\n",
    "    plot_per_token_mean(np_prompt_embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e3d793-7b4c-4ea0-a727-01abf0a50e41",
   "metadata": {},
   "source": [
    "### Short Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027bb3b9-5335-4400-831c-178d6c7a02ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prompt_embed_properties(prompt_embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0144cc65-1614-4ce9-ac18-2026848a57a3",
   "metadata": {},
   "source": [
    "### Long Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b930a971-20e3-4662-978f-ff3d671c0caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_prompt = f\"cinematic still {prompt} . emotional, harmonious, vignette, 4k epic detailed, shot on kodak, 35mm photo, sharp focus, high budget, cinemascope, moody, epic, gorgeous, film grain, grainy\"\n",
    "long_prompt_embeds, long_negative_prompt_embeds = pipeline.encode_prompt(\n",
    "    long_prompt,\n",
    "    device=\"cuda\",\n",
    "    num_images_per_prompt=1,\n",
    "    do_classifier_free_guidance=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c502b3-4dd8-449e-ba12-2188a523456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prompt_embed_properties(long_prompt_embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0d17f-1e39-44f9-a26e-f434990203d4",
   "metadata": {},
   "source": [
    "### Negative (Empty) Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8ebe71-e523-46f6-98ff-ef51622879b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prompt_embed_properties(negative_prompt_embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4215fff7-4fb3-4eb5-8700-59cad6412d4f",
   "metadata": {},
   "source": [
    "## Prompt Embed Modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6870ccef-26f2-4e19-9e98-597ba2081d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use style prompts to determine directions\n",
    "# prompts = [\n",
    "#     \"a bouquet of flowers\",\n",
    "#     \"a man\",\n",
    "#     \"a futuristic concrete bunker\", \n",
    "# ]\n",
    "prompt = \"a woman wearing a hat\"\n",
    "style_prompts = [\n",
    "    \". cinematic still, emotional, harmonious, vignette, highly detailed, high budget, bokeh, cinemascope, moody, epic, gorgeous, film grain, grainy\",\n",
    "    \". anime artwork, anime style, key visual, vibrant, studio anime,  highly detailed\",\n",
    "    \". graphic illustration, comic art, graphic novel art, vibrant, highly detailed\",\n",
    "    \". neonpunk style, cyberpunk, vaporwave, neon, vibes, vibrant, stunningly beautiful, crisp, detailed, sleek, ultramodern, magenta highlights, dark purple shadows, high contrast, cinematic, ultra detailed, intricate, professional\",\n",
    "    \". psychedelic style, vibrant colors, swirling patterns, abstract forms, surreal, trippy\",\n",
    "]\n",
    "\n",
    "with torch.no_grad():\n",
    "    base_embeds = pipeline.encode_prompt(\n",
    "        prompt,\n",
    "        device=\"cuda\",\n",
    "        num_images_per_prompt=1,\n",
    "        do_classifier_free_guidance=True,\n",
    "    )\n",
    "    \n",
    "#     style_embeds = []\n",
    "#     for style_prompt in style_prompts:\n",
    "#         merged_prompt = prompt + \" \" + style_prompt\n",
    "#         style_embeds.append(\n",
    "#             pipeline.encode_prompt(\n",
    "#                 merged_prompt,\n",
    "#                 device=\"cuda\",\n",
    "#                 num_images_per_prompt=1,\n",
    "#                 do_classifier_free_guidance=True,\n",
    "#             )\n",
    "#         )\n",
    "    \n",
    "#     style_directions = []\n",
    "#     for style_embed in style_embeds:\n",
    "#         style_direction = style_embed[0] - base_embeds[0]\n",
    "#         #style_direction = torch.nn.functional.normalize(style_direction, p=2.0, dim=0)\n",
    "#         style_directions.append(style_direction)\n",
    "\n",
    "# style_directions = torch.cat(style_directions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bfc29f-5a4c-41c3-98af-3986efc05ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.tensor(\n",
    "    [\n",
    "        0.0, # Cinematic\n",
    "        5.0, # Anime\n",
    "        0.0, # Comic\n",
    "        0.0, # Cyberpunk\n",
    "        2.0, # Psychedelic\n",
    "    ],\n",
    "    dtype=base_embeds[0].dtype,\n",
    "    device=base_embeds[0].device,\n",
    ")\n",
    "alpha = 0.0\n",
    "\n",
    "changed_prompt_embeds = base_embeds[0].clone()\n",
    "if weights.max() > 0.00001:\n",
    "    weights = torch.nn.functional.normalize(weights, p=2.0, dim=0)\n",
    "    weights = weights.reshape((weights.shape[0], 1, 1))\n",
    "    changed_prompt_embeds = changed_prompt_embeds + (style_directions * weights).sum(dim=0) * alpha\n",
    "generate_image(changed_prompt_embeds, base_embeds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5395d6-abb4-4d1f-ac2e-f2117aa4af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a range of token embeddings to 0s\n",
    "with torch.no_grad():\n",
    "    changed_prompt_embeds = prompt_embeds.clone()\n",
    "    changed_prompt_embeds[:, 1:30, :] = 0.0\n",
    "\n",
    "generate_image(changed_prompt_embeds, negative_prompt_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d35cc8e-d248-4b32-a09e-8968ab0726de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a random 'token' direction. Apply the same direction offset to all tokens.\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # Random value in range [0, 1).\n",
    "    #random_direction = torch.rand_like(changed_prompt_embeds)\n",
    "    torch.manual_seed(0)\n",
    "    random_direction = torch.rand(\n",
    "        (prompt_embeds.shape[-1],),\n",
    "        dtype=prompt_embeds.dtype,\n",
    "        device=prompt_embeds.device,\n",
    "        \n",
    "    )\n",
    "    # Shift to [-0.5, 0.5).\n",
    "    random_direction = random_direction - 0.5\n",
    "    # Normalize to unit vector.\n",
    "    random_direction = torch.nn.functional.normalize(random_direction, p=2.0, dim=0)\n",
    "\n",
    "    for alpha in [4, 6, 8, 10]:\n",
    "        changed_prompt_embeds = prompt_embeds.clone()\n",
    "        changed_prompt_embeds = changed_prompt_embeds + random_direction * alpha\n",
    "        plt.imshow(generate_image(changed_prompt_embeds, negative_prompt_embeds))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d567b9-c5c4-42eb-a62c-f332549b37c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a random 'token' direction. Apply the same direction offset to a subset of all tokens.\n",
    "# Choose a random direction for the embedding tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca3ec13-bdfc-4196-bfe6-7faaf0b9ab5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
