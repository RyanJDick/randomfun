{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383a446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca9febb",
   "metadata": {},
   "source": [
    "# Test Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7c224f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, UNet2DConditionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a21fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
    "\n",
    "unet = UNet2DConditionModel.from_pretrained(\n",
    "    \"/data/finetune/t2i/living_room/20230615-012615/checkpoint-500/unet\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "# if you have trained with `--args.train_text_encoder` make sure to also load the text encoder\n",
    "#text_encoder = CLIPTextModel.from_pretrained(\"/sddata/dreambooth/daruma-v2-1/checkpoint-100/text_encoder\")\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    unet=unet,\n",
    "    safety_checker=None,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963db0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt = \"interior design, living room, brown leather couch, high res, 4k\"\n",
    "prompt = \"Yoda\"\n",
    "#prompt = \"man riding a horse\"\n",
    "seed = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1caf30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator(device=\"cuda\").manual_seed(seed)\n",
    "\n",
    "image = pipe(\n",
    "    prompt=prompt,\n",
    "    generator=generator,\n",
    "    num_inference_steps=50,\n",
    ").images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8a0280",
   "metadata": {},
   "source": [
    "# Test Merged Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306ccae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, UNet2DConditionModel\n",
    "from utils.merge_weights import merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8687219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    safety_checker=None,\n",
    "    torch_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd073b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet2DConditionModel.from_pretrained(\n",
    "    \"/data/finetune/t2i/living_room/20230615-012615/checkpoint-1000/unet\",\n",
    "    torch_dtype=torch.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d8bd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_unet = merge(pipe.unet, unet, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef03545",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f32b2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt = \"interior design, living room, brown leather couch, high res, 4k\"\n",
    "prompt = \"Yoda\"\n",
    "#prompt = \"man riding a horse\"\n",
    "seed = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642f3454",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator(device=\"cuda\").manual_seed(seed)\n",
    "\n",
    "image = pipe(\n",
    "    prompt=prompt,\n",
    "    generator=generator,\n",
    "    num_inference_steps=50,\n",
    ").images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a4cf5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
