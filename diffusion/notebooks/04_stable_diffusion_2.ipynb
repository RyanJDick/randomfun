{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f95d743d",
   "metadata": {},
   "source": [
    "# SD2 Text-to-Image 768x768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64b8b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\n",
    "import torch\n",
    "\n",
    "repo_id = \"stabilityai/stable-diffusion-2\"\n",
    "pipe = DiffusionPipeline.from_pretrained(repo_id, torch_dtype=torch.float16, revision=\"fp16\")\n",
    "\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8da9c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"High quality photo of an astronaut riding a horse in space\"\n",
    "generator = torch.Generator(\"cuda\").manual_seed(1)\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    guidance_scale=9,\n",
    "    num_inference_steps=25,\n",
    "    generator=generator,\n",
    ").images[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e4452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c39ec5",
   "metadata": {},
   "source": [
    "# SD2 Inpainting 512x512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb9b750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import requests\n",
    "import torch\n",
    "from io import BytesIO\n",
    "\n",
    "from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\n",
    "\n",
    "\n",
    "def download_image(url):\n",
    "    response = requests.get(url)\n",
    "    return PIL.Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "\n",
    "img_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png\"\n",
    "mask_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png\"\n",
    "\n",
    "init_image = download_image(img_url).resize((512, 512))\n",
    "mask_image = download_image(mask_url).resize((512, 512))\n",
    "\n",
    "repo_id = \"stabilityai/stable-diffusion-2-inpainting\"\n",
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    repo_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    revision=\"fp16\",\n",
    ")\n",
    "\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a522d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a97767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acada626",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Face of a yellow cat, high resolution, sitting on a park bench\"\n",
    "image = pipe(\n",
    "    prompt=prompt,\n",
    "    image=init_image,\n",
    "    mask_image=mask_image,\n",
    "    num_inference_steps=25\n",
    ").images[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625c4ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dc1e9d",
   "metadata": {},
   "source": [
    "# SD2 Super Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a017653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from diffusers import StableDiffusionUpscalePipeline\n",
    "import torch\n",
    "\n",
    "# load model and scheduler\n",
    "model_id = \"stabilityai/stable-diffusion-x4-upscaler\"\n",
    "pipeline = StableDiffusionUpscalePipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "pipeline = pipeline.to(\"cuda\")\n",
    "\n",
    "# let's download an  image\n",
    "url = \"https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/sd2-upscale/low_res_cat.png\"\n",
    "response = requests.get(url)\n",
    "low_res_img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "low_res_img = low_res_img.resize((128, 128))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c7b944",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_res_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eacbc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a white cat\"\n",
    "upscaled_image = pipeline(prompt=prompt, image=low_res_img).images[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae98704",
   "metadata": {},
   "outputs": [],
   "source": [
    "upscaled_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4803cb49",
   "metadata": {},
   "source": [
    "# SD2 Depth-to-Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a693ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "from diffusers import StableDiffusionDepth2ImgPipeline\n",
    "\n",
    "pipe = StableDiffusionDepth2ImgPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-2-depth\",\n",
    "    torch_dtype=torch.float16,\n",
    ").to(\"cuda\")\n",
    "\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "init_image = Image.open(requests.get(url, stream=True).raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31c1363",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0470c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"two tigers\"\n",
    "n_prompt = \"bad, deformed, ugly, bad anotomy\"\n",
    "image = pipe(prompt=prompt, image=init_image, negative_prompt=n_prompt, strength=0.7).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1699b9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccea741a",
   "metadata": {},
   "source": [
    "# SD Pix2Pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687b1a34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "import requests\n",
    "import torch\n",
    "from diffusers import StableDiffusionInstructPix2PixPipeline\n",
    "\n",
    "model_id = \"timbrooks/instruct-pix2pix\"\n",
    "pipe = StableDiffusionInstructPix2PixPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(\"cuda\")\n",
    "\n",
    "url = \"https://huggingface.co/datasets/diffusers/diffusers-images-docs/resolve/main/mountain.png\"\n",
    "\n",
    "\n",
    "def download_image(url):\n",
    "    image = PIL.Image.open(requests.get(url, stream=True).raw)\n",
    "    image = PIL.ImageOps.exif_transpose(image)\n",
    "    image = image.convert(\"RGB\")\n",
    "    return image\n",
    "\n",
    "\n",
    "image = download_image(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7e90e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6fde41",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"snow covered peaks, snowy, rocky, lots of snow, dark\"\n",
    "generator = torch.Generator(\"cuda\").manual_seed(5)\n",
    "out_image = pipe(\n",
    "    prompt,\n",
    "    image=image,\n",
    "    num_inference_steps=30,\n",
    "    image_guidance_scale=1.3,\n",
    "    guidance_scale=12,\n",
    "    generator=generator,\n",
    ").images[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d51831",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0538f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Morning:\n",
    "# - try out the youtube demo\n",
    "# - try depth2img\n",
    "# - figure out what the parameters in img2img do\n",
    "# - figure out how to do depth2img\n",
    "\n",
    "# - See if --xformers helps webui perf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
